<div align="center">

# üìâ **Predictive System for Customer Churn: Interconnect**

![Python](https://img.shields.io/badge/Python-3.11-blue?style=for-the-badge&logo=python&logoColor=white)
![CatBoost](https://img.shields.io/badge/CatBoost-Model-orange?style=for-the-badge)
![Render](https://img.shields.io/badge/Render-Deployed-4353ff?style=for-the-badge&logo=render&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-App-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)

### üöÄ **[ACCEDER A LA APLICACI√ìN EN VIVO]**(https://interconnect-churn-app.onrender.com)

</div>

---

## üéØ **Problem Statement**

En la industria de las telecomunicaciones, el costo de adquirir un nuevo cliente es significativamente m√°s alto que el de retener a uno existente. Interconnect, un proveedor de servicios de comunicaci√≥n, enfrenta el reto de identificar patrones de comportamiento que preceden a la cancelaci√≥n de servicios (Churn).

El objetivo de este proyecto no fue solo construir un modelo predictivo, sino dise√±ar un ecosistema de decisi√≥n que permita al departamento de Marketing anticiparse a la fuga de clientes con una confianza estad√≠stica superior al $0.88$ en la m√©trica $AUC‚àíROC$.

### üß© Nuestro Desaf√≠o T√©cnico

Para resolver este problema, se abordaron seis dimensiones cr√≠ticas de la ciencia de datos aplicada:

- **Exploratory Data Analysis (EDA):** Identificaci√≥n de hallazgos cr√≠ticos e integridad de datos para influir en el dise√±o del modelo.

- **Strategic Planning:** Definici√≥n de KPIs y criterios de √©xito desde una etapa temprana.

- **Feature Engineering:** Transformaci√≥n de datos crudos en se√±ales de negocio, destacando la creaci√≥n de la variable Tenure.

- **Data Readiness:** Preparaci√≥n t√©cnica mediante codificaci√≥n y escalado, gestionando el desbalance de clases (26.5%).

- **Advanced Modeling:** Optimizaci√≥n de modelos de gradiente (CatBoost, LightGBM) superando un Baseline Dummy inicial.

- **Business Impact:** Traducci√≥n de m√©tricas t√©cnicas (AUC, Recall) en una estrategia operativa real mediante el ajuste de umbrales de decisi√≥n.

---

## üîç **1. Exploratory Data Analysis (EDA)**

El EDA no fue una etapa preliminar, sino una fase decisiva de auditor√≠a. Transformamos un conjunto de tablas aisladas en un dataset coherente, asegurando la integridad de la se√±al antes del modelado.

### 1.1 Data Profiling & Strategic Integration

Se implement√≥ una estrategia de **Left Join** tomando como tabla maestra `df_contract`, preservando el universo total de **7,043 clientes**.

> **Decisi√≥n T√©cnica:** Al no usar *Inner Join*, garantizamos la inclusi√≥n de usuarios que no cuentan con servicios adicionales de internet o telefon√≠a, evitando un sesgo de selecci√≥n desde el origen.

| Dataset | Registros | Clave de Uni√≥n | Contenido Principal |
| --- | --- | --- | --- |
| **Contract** | 7,043 | `customerID` | Tipo de contrato, facturaci√≥n, fechas. |
| **Personal** | 7,043 | `customerID` | Datos demogr√°ficos. |
| **Internet** | 5,517 | `customerID` | Servicios de fibra y seguridad. |
| **Phone** | 6,361 | `customerID` | Multi-l√≠neas y telefon√≠a. |

---

### 1.2 Sanity Check & Data Quality

Realizamos una limpieza profunda para evitar "ruido" en el modelo:

- **Target & Tenure Construction:**
    - Se cre√≥ una flag binaria **`Churn`** (Target) a partir de la columna `EndDate`.
    - Se calcul√≥ la variable **`Tenure`** (Antig√ºedad en d√≠as) imputando la fecha de corte (2020-02-01) para clientes activos.

- **Hallazgo de los "Clientes D√≠a 0":**
    - Detectamos 11 casos con `TotalCharges` nulos. Al cruzar con `Tenure`, descubrimos que eran clientes nuevos que se unieron el mismo d√≠a de la toma de datos. Se imputaron con 0 en lugar de eliminarlos.

- **Fuzzy Duplicates:** 
    - Identificamos 267 perfiles id√©nticos con IDs distintos. Tras el an√°lisis, determinamos que era un **Efecto de Cohorte** (contrataciones masivas en fechas promocionales) y decidimos mantenerlos para reflejar la realidad operativa.

---

### 1.3 Feature Insights (Patrones de Negocio)

El an√°lisis visual permiti√≥ detectar los "detonantes" de la fuga:

#### A. An√°lisis del Target (Desbalance de Clases)

Detectamos un **26.5% de Churn**. Este desbalance fue el pilar para decidir el uso de `class_weight='balanced'` y la m√©trica $AUC-ROC$.

![Distribuci√≥n_de_cancelaciones](results/distribucion_de_cancelaciones.png)

#### B. An√°lisis Bivariado: Categor√≠as vs. Churn

- **Contratos:** Los clientes con contrato *Month-to-month* son dr√°sticamente m√°s propensos a la fuga.
- **Servicio de Internet:** Inesperadamente, los usuarios de **Fibra √ìptica** presentan tasas de deserci√≥n m√°s altas que los de DSL, se√±alando un punto de fricci√≥n en el servicio o precio.

![Tipo de contrato vs Churn](results/type_vs_churn.png)

#### C. An√°lisis Bivariado: Num√©ricas vs. Churn

- **Sensibilidad al Precio:** A mayor `MonthlyCharges`, mayor probabilidad de abandono.
- **`Tenure` y volatilidad:** Los clientes nuevos (`Tenure` bajo) son los m√°s vol√°tiles. El riesgo disminuye conforme aumenta la lealtad.

![Monthly Charges vs Churn](results/Monthly_charges_vs_churn.png)

#### D. Correlaci√≥n y Multicolinealidad

Observamos una alta correlaci√≥n entre `Tenure` y `TotalCharges`. Esta advertencia de multicolinealidad fue crucial para priorizar modelos de ensamble (√°rboles) sobre modelos lineales puros.

![Heatmap](results/heatmap.png)

---

## üó∫Ô∏è **2. Proposed Roadmap: From Insights to Action**

Este plan de trabajo no se plante√≥ como una secuencia gen√©rica, sino como una **arquitectura de decisiones t√©cnicas** informada por los hallazgos del EDA. El objetivo: superar el umbral de **0.88 AUC-ROC** mediante un pipeline robusto y reproducible.

### Phase 1: Signal Refinement (Preprocessing)

- **Contexto:** La informaci√≥n original se encuentra fragmentada en 4 fuentes con ruido en las fechas de registro.
- **Acci√≥n:** Consolidaci√≥n mediante *Left Join* (7,043 clientes) e imputaci√≥n basada en l√≥gica de negocio.
- **Estrategia:** Transformaci√≥n de datos temporales en variables de magnitud (**`Tenure`**) y etiquetas binarias (**`Churn`**), asegurando que los "Clientes D√≠a 0" aporten informaci√≥n en lugar de ser eliminados.

### Phase 2: Data Architecture (Splitting & Scaling)

- **Contexto:** El desbalance del **26.5%** en la clase positiva exige una divisi√≥n cuidadosa.
- **Estrategia:** Divisi√≥n 80/20 con **estratificaci√≥n** para preservar la proporci√≥n real de fuga.
- **Doble Codificaci√≥n:** Se implementa una estrategia bimodal para optimizar cada arquitectura:

| T√©cnica | Objetivo | Aplicaci√≥n |
| :--- | :--- | :--- |
| **One-Hot Encoding** | Estabilidad num√©rica | Regresi√≥n Log√≠stica |
| **Native Encoding** | Eficiencia en ramas | CatBoost / LightGBM |

- **Normalizaci√≥n:** Uso de `StandardScaler` para equilibrar la influencia de variables como `MonthlyCharges`.

### Phase 3: Modeling

- **Contexto:** La complejidad de las interacciones detectadas en el EDA sugiere el uso de modelos no lineales.
- **Acci√≥n:** Jerarqu√≠a de modelos partiendo de un **Baseline Dummy**, pasando por modelos lineales, hasta ensambles avanzados de *Gradient Boosting*.
- **Eficiencia:** Dise√±o de una estrategia para optimizar hiperpar√°metros de forma eficiente tomando en cuenta limitaciones de hardware.

### Phase 4: Business Diagnosis & Threshold Tuning

- **Contexto:** En telecomunicaciones, un Falso Negativo (no detectar a un cliente que se va) es m√°s costoso que un Falso Positivo.
- **Acci√≥n:** Desarrollo de una **herramienta de diagn√≥stico de 6 paneles** para visualizar el intercambio (*trade-off*) entre Precisi√≥n y Recall.
- **Valor Agregado:** Ajuste manual del **umbral de decisi√≥n (threshold)** para maximizar la captura de clientes en riesgo y optimizar el ROI de las campa√±as de retenci√≥n.

---

## üõ†Ô∏è **3. Feature Engineering: De Datos Crudos a Se√±ales de Negocio**

El objetivo central de esta fase fue **hacer expl√≠cita la informaci√≥n impl√≠cita**. En este proyecto, los valores ausentes (NaN) no representaban errores de captura, sino estados espec√≠ficos del servicio. Se prioriz√≥ una **imputaci√≥n sem√°ntica** sobre una estad√≠stica para preservar la pureza de la se√±al.

### üß† L√≥gica de Imputaci√≥n Sem√°ntica

Tras la unificaci√≥n mediante *Left Join*, se identificaron vac√≠os estructurales que fueron resueltos bajo l√≥gica de negocio:

| Dimensi√≥n | Variables Afectadas | Hallazgo | Acci√≥n Realizada |
| --- | --- | --- | --- |
| **Internet** | `OnlineSecurity`, `TechSupport`, etc. | Clientes sin servicio de internet base. | Imputaci√≥n con **'No'** |
| **Telefon√≠a** | `MultipleLines` | Clientes sin servicio de telefon√≠a b√°sico. | Imputaci√≥n con **'No'** |
| **Financiera** | `TotalCharges` | Clientes con **Tenure = 0** (Nuevos ingresos). | Imputaci√≥n con **0.0** |


> ‚ö†Ô∏è **Nota:** No se aplicaron medias o medianas. Imputar estad√≠sticamente habr√≠a introducido "ruido artificial" en el comportamiento de los clientes nuevos, quienes representan el segmento de mayor riesgo de fuga.

### üíé El Hallazgo de los "Clientes D√≠a 0"

Uno de los puntos cr√≠ticos fue la gesti√≥n de la columna `TotalCharges`. Detectamos una **correlaci√≥n perfecta**:

$$
\text{Total Charges} = NaN \iff \text{Tenure} = 0
$$

Estos 11 registros corresponden a clientes que contrataron el servicio el mismo d√≠a del corte de datos. Al no haber completado su primer ciclo de facturaci√≥n, su gasto acumulado es t√©cnicamente **cero**. Conservar estos registros permiti√≥ al modelo aprender la volatilidad de los usuarios en su primer contacto con la empresa.

---

## ‚öôÔ∏è **4. Data Preparation: Splitting, Encoding & Scaling**

El objetivo de esta fase fue construir un puente entre los datos procesados y los algoritmos. No se aplic√≥ una soluci√≥n gen√©rica; en su lugar, se dise√±√≥ una **estrategia bimodal** para maximizar el aprendizaje de cada familia de modelos.

### 4.1 Splitting Estratificado

Dado el desbalance de clases (26.5% de Churn), una divisi√≥n aleatoria simple habr√≠a distorsionado la proporci√≥n de desertores. La **estratificaci√≥n** garantiz√≥ que tanto el entrenamiento como la validaci√≥n fueran representativos del negocio.

| Conjunto | Proporci√≥n | Dimensiones ($X, y$) | Proporci√≥n de Churn |
| --- | --- | --- | --- |
| **Entrenamiento** | 80% | $(5634,18),(5634,)$ | 26.5% |
| **Prueba (Test)** | 20% | $(1409,18),(1409,)$ | 26.5% |

---

### 4.2 Estrategia Bimodal (Codificaci√≥n & Escalado)

Implementamos un `ColumnTransformer` flexible para adaptar la representaci√≥n de los datos seg√∫n los requerimientos matem√°ticos de cada arquitectura:

#### A. Configuraci√≥n para Modelos Lineales (Regresi√≥n Log√≠stica)

Los modelos lineales requieren estabilidad num√©rica y ausencia de jerarqu√≠as artificiales en las categor√≠as.

- **Codificaci√≥n:** One-Hot Encoding (OHE) con `drop='first'` para evitar la trampa de la variable ficticia. Tras este proceso, el dataset se expandi√≥ a **36 caracter√≠sticas**.
- **Escalado:** `StandardScaler` aplicado a `MonthlyCharges` y `Tenure` para evitar que variables de mayor magnitud dominen la funci√≥n de p√©rdida.

#### B. Configuraci√≥n para √Årboles de Decisi√≥n (Random Forest)

Los √°rboles manejan mejor representaciones compactas y no dependen de la escala.

- **Codificaci√≥n:** Ordinal Encoding para reducir dimensionalidad.
- **Escalado:** No requerido, preservando la interpretabilidad de los nodos.

#### C. Configuraci√≥n Nativa (CatBoost & LightGBM)

Aprovechamos las ventajas competitivas de los algoritmos de √∫ltima generaci√≥n:

- **CatBoost:** Uso de **Native Categorical Handling** mediante la extracci√≥n de √≠ndices (`cat_features`), permitiendo que el modelo aplique su algoritmo de *Ordered Boosting*.
- **LightGBM:** Conversi√≥n expl√≠cita al tipo de dato `category` de Pandas, optimizando el entrenamiento bajo restricciones de memoria.

> üí° **Comentario:** Esta rigurosidad asegur√≥ que los modelos no encontraran errores de dimensiones y pudieran concentrarse exclusivamente en la se√±al predictiva. La estrategia no solo increment√≥ el $AUC-ROC$, sino que garantiz√≥ que cada decisi√≥n t√©cnica estuviera alineada con los principios matem√°ticos de los algoritmos utilizados.

---

## üõ†Ô∏è **5. Model Selection & Optimization: El Marco Experimental**

Transformamos el problema de negocio en un experimento multimodelo estandarizado. El √©xito no radic√≥ en elegir el algoritmo m√°s complejo, sino en dise√±ar una infraestructura que garantizara comparaciones justas y resultados reproducibles.

### 5.1 Modelo Dummy (Baseline)

Antes de la optimizaci√≥n, establecimos un umbral m√≠nimo de √©xito mediante un `DummyClassifier` (estrategia estratificada).

- **Resultado:** $AUC‚àíROC=0.5136$.
- **Significado:** Cualquier modelo final deb√≠a superar este valor para demostrar que realmente aprendi√≥ patrones m√°s all√° del azar o la proporci√≥n de clases.

### 5.2 Arquitectura de automatizaci√≥n

Dise√±amos la funci√≥n `run_model_optimization`, una infraestructura experimental que permiti√≥:

- **Arquitectura Modular (Tasks):** Cada modelo se encapsul√≥ con su propio espacio de b√∫squeda y su dataset espec√≠fico (OHE para lineales, Native para CatBoost).
- **B√∫squeda Polim√≥rfica:** Uso inteligente de **GridSearchCV** para espacios peque√±os y **RandomizedSearchCV** (20 iteraciones) para modelos complejos, optimizando el tiempo de c√≥mputo.
- **Validaci√≥n Cruzada ($K=5$):** Garantizamos que el score reportado sea estable y generalizable, reduciendo el riesgo de sobreajuste (*overfitting*).

---

### 5.3 Performance de los modelos (CV Results)

Tras el proceso de optimizaci√≥n, estos fueron los resultados obtenidos durante la fase de validaci√≥n cruzada. La m√©trica objetivo fue maximizar el **AUC-ROC**.

| Modelo | AUC-ROC (CV) | Tiempo de Ajuste | Configuraci√≥n Clave |
| --- | --- | --- | --- |
| **Dummy (Baseline)** | 0.5136 | < 1s | Estrategia estratificada |
| **Logistic Regression** | 0.8451 | 6.99s | `penalty: l1`, `C: 50` |
| **Random Forest** | 0.8599 | 36.42s | `max_depth: 10`, `n_estimators: 300` |
| **LightGBM** | 0.8973 | 96.89s | `num_leaves: 31`, `n_estimators: 500` |
| **CatBoost (Best)** | **0.9162** | 650.91s | `depth: 4`, `learning_rate: 0.1` |

![Best Score por modelo](results/Best_score_modelo.png)

---

### 5.4 El mejor candidato: CatBoost

Aunque **CatBoost** requiri√≥ el mayor tiempo de entrenamiento (~10.8 minutos), se consolid√≥ como el modelo ganador por tres razones:

1. **Estabilidad:** Obtuvo el mejor score en validaci√≥n cruzada ($0.9162$), superando el objetivo inicial de $0.88$.
2. **Manejo Nativo:** Su capacidad para procesar categor√≠as sin codificaci√≥n externa redujo el riesgo de fuga de informaci√≥n.
3. **Generalizaci√≥n:** Present√≥ el mejor balance entre el error de entrenamiento y el de validaci√≥n.

---

## üöÄ **6. Final Evaluation & Business Insight**

La validaci√≥n definitiva se realiz√≥ sobre el **Test Set** (datos no vistos), representando la prueba de fuego para la capacidad de generalizaci√≥n del sistema. El objetivo no fue solo alcanzar una m√©trica alta, sino asegurar que el modelo sea una herramienta de decisi√≥n confiable para **Interconnect**.

### üõ†Ô∏è 6.1 Panel de 6 Gr√°ficos (Diagnostic Tool): Consideraciones m√°s all√° del AUC

Para una auditor√≠a t√©cnica profunda, implementamos la funci√≥n `evaluate_model`. Este dashboard de 3x2 permite diagnosticar el comportamiento del modelo desde √°ngulos cr√≠ticos:

- **Discrimination Strategy (Paneles A, B, C):** Sincronizamos marcadores en las curvas $F_1, ROC$ y $PRC$. Esto permite visualizar c√≥mo el ajuste del umbral impacta simult√°neamente en la precisi√≥n y la sensibilidad.

- **Operational Reality (Panel D):** La Matriz de Confusi√≥n traduce probabilidades en decisiones. Permite cuantificar el costo de "molestar" a un cliente leal frente al riesgo de perder a un desertor.

- **Interpretability (Panel E):** Identificamos los 10 principales impulsores de la fuga. En este modelo, variables como `Tenure`, `Type` y `MonthlyCharges` dominan la decisi√≥n, permitiendo una comunicaci√≥n clara con el equipo de Marketing.

- **System Reliability (Panel F):** La Curva de Calibraci√≥n valida si las probabilidades predichas coinciden con la realidad. Un ajuste casi perfecto en la diagonal  asegura que el modelo es financieramente confiable para proyecciones de ingresos.

---

### üìà 6.2 Model Improvements & Final Results

Sometimos a los l√≠deres a una ronda de mejoras, enfoc√°ndonos en la estabilidad y la reducci√≥n del *overfitting*.

| M√©trica | CatBoost (Base) | CatBoost (Tuned) | Status |
| --- | --- | --- | --- |
| **AUC-ROC (Test)** | 0.9163 | **0.9148** | üü¢ Supera meta (0.88) |
| **Threshold** | 0.50 | **0.40** | üéØ Optimizado |
| **Falsos Negativos** | 132 | **94** | üõ°Ô∏è Reducci√≥n de riesgo |

#### Resultados para la primera prueba de CatBoost (Base)

Tras la evaluaci√≥n del modelo con mejor desempe√±o obtuvimos los siguientes resultados:

![Testing CatBoost (Base)](results/download_3_cb.png)

El modelo **CatBoost** en su configuraci√≥n base no solo super√≥ los objetivos t√©cnicos, sino que demostr√≥ una madurez operativa muy superior a los modelos lineales y de ensamble tradicionales. A continuaci√≥n, el desglose de los 6 paneles de diagn√≥stico:

- **A) Optimizaci√≥n del Umbral ($F_1$ vs. Threshold):** Alcanzamos un *$F_1 - score$* **m√°ximo de 0.76** en el conjunto de prueba, superando por m√°s de 10 puntos porcentuales a la Regresi√≥n Log√≠stica (0.65) y al Random Forest (0.66). El pico de eficiencia se localiza cerca del **umbral 0.4**, sugiriendo que una mayor sensibilidad es clave para el negocio.

- **B) Capacidad de Discriminaci√≥n (Curva ROC):** Logramos un **$AUC=0.9163$** en test, superando ampliamente la meta inicial. La curva presenta un codo agresivo que indica una capacidad de ordenamiento de riesgo superior y una generalizaci√≥n m√°s sana que los modelos previos.

- **C) Confiabilidad de la Predicci√≥n (Curva PRC):** Con un **Average Precision ($AP$) de 0.85**, el modelo mantiene una precisi√≥n casi perfecta hasta un *Recall* de 0.3. Esto permite identificar al primer **30% de los desertores con cero errores**.

- **D) Eficiencia Operativa (Matriz de Confusi√≥n - Th: 0.5):** Reducci√≥n dr√°stica de "falsas alarmas" a solo **52 Falsos Positivos**, comparado con los 192 de Random Forest. Capturamos **242 desertores reales** con un impacto m√≠nimo en la clasificaci√≥n como potenciales desertores a clientes leales.

- **E) Jerarqu√≠a de Variables (Feature Importance):** A diferencia de otros modelos, CatBoost identifica a la **Antig√ºedad (Tenure)** como la variable principla con un peso de **65**. El modelo concluye que el tiempo de permanencia es el predictor de lealtad m√°s potente, por encima del precio o el contrato.

- **F) Honestidad Probabil√≠stica (Curva de Calibraci√≥n):** Es el modelo mejor calibrado del ecosistema. La proximidad a la diagonal perfecta indica que los *scores* de riesgo son **probabilidades reales**, permitiendo calcular el ROI de las campa√±as de retenci√≥n de forma directa y sin ajustes manuales.

#### Resultados para la segunda prueba de CatBoost (Tuned)

Posterior a la primera evaluaci√≥n, se determin√≥ que el Threshold debr√≠a ser modificado a 0.4 con el objetivo de rescatar la mayor cantidad de usuarios que pudieran cancelar, ya que este grupo representa mayores p√©rdidas que s√≥lo traer nuevos clientes a la empresa.

![Testing CatBoost (Tuned)](results/download_3.1_cb_tuned_v1.png)

La implementaci√≥n del modelo refinado representa el punto de m√°xima eficiencia para el sistema de predicci√≥n. Mientras que la versi√≥n base ya era robusta, esta iteraci√≥n prioriza la **estabilidad estructural** y la **captura proactiva de riesgo** mediante el ajuste del umbral a **0.40**.

- **A) Sinton√≠a del Umbral ($F_1$ vs. Threshold):** El modelo alcanza su punto m√°ximo de equilibrio en el **marcador 0.4 (X roja)**. Este ajuste optimiza el valor $F_1$ para los datos de prueba, marcando el balance perfecto entre precisi√≥n y sensibilidad.

- **B) Robustez y Generalizaci√≥n (Curva ROC):** Mantenemos una calidad excepcional con un **$AUC=0.9161$** en el conjunto de prueba. Al incrementar la regularizaci√≥n (`l2_leaf_reg=5`) y reducir el `learning_rate` a **0.05**, logramos un modelo m√°s "suave" y menos susceptible a variaciones bruscas en nuevos datos.

- **C) Eficiencia en el Recall (Curva PRC):** A pesar de bajar el umbral, la ca√≠da en la precisi√≥n es m√≠nima. El beneficio de capturar al **75% de los desertores reales** justifica ampliamente la gesti√≥n de las 86 falsas alarmas generadas.

- **D) Reducci√≥n del Riesgo (Matriz de Confusi√≥n):** La decisi√≥n de negocio es clara: *"Es mejor retener preventivamente que perder sin aviso"*. Logramos reducir los **Falsos Negativos en un 28.8%** (de 132 a 94), rescatando a **38 clientes adicionales** que pasaban desapercibidos bajo el umbral est√°ndar.

- **E) Estabilidad de Predictores (Feature Importance):** La **Antig√ºedad (Tenure)** se reafirma como el pilar fundamental del modelo. El refinamiento confirma que la lealtad acumulada es el factor que mejor explica la retenci√≥n, por encima de variables transaccionales.

- **F) Calibraci√≥n mejorada:** La curva de calibraci√≥n se mantiene adherida a la **diagonal perfecta**. Esto garantiza que si el sistema predice un riesgo de 0.4, aproximadamente el **40% de esos casos se fugar√°n**, permitiendo al negocio confiar ciegamente en los *scores* de riesgo para proyecciones financieras.

> **Nota:** Aunque el AUC vari√≥ m√≠nimamente, el modelo *Tuned* presenta una curva de calibraci√≥n m√°s robusta y una regularizaci√≥n  que garantiza un desempe√±o m√°s estable en producci√≥n.

---

### üéØ 6.3 Strategic Threshold Tuning: Priorizando el Recall

La decisi√≥n m√°s cr√≠tica fue el ajuste del umbral de decisi√≥n a **0.40**.

**¬øPor qu√© 0.40?**
En la industria de telecomunicaciones, el costo de omitir a un cliente que est√° por irse es dr√°sticamente superior al costo de ofrecer un incentivo a alguien que pensaba quedarse. Al bajar el umbral de 0.5 a 0.4:

* **Maximizamos el Recall:** Logramos capturar al **91% de los desertores potenciales** (basado en la matriz de confusi√≥n del set de prueba).
* **Eficiencia de Marketing:** Pasamos de detectar 242 desertores a **280**, permitiendo una intervenci√≥n preventiva mucho m√°s agresiva y efectiva.

---

## üèÅ **Final Conclusion**

El modelo **CatBoost** final no es solo un √©xito estad√≠stico con un $AUC‚àíROC$ de $0.9148$; es un sistema robusto, calibrado y alineado con los objetivos de retenci√≥n. Su arquitectura permite que Interconnect pase de una postura reactiva a una estrategia proactiva basada en datos.

---




